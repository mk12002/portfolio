{
  "projects": [
    {
      "slug": "hybex-law",
      "title": "HybEx-Law: Hybrid Legal AI Engine",
      "category": "Legal AI",
      "tagline": "LegalBERT + GNN + Prolog hybrid reasoning system",
      "metric": "F1 Score: 0.985",
      "precision": "98.48%",
      "tags": ["Legal NLP", "Symbolic AI", "GNN", "Hybrid Models", "Prolog", "LegalBERT"],
      "description": "A hybrid AI system integrating LegalBERT embeddings, GNN-based graph reasoning, and Prolog rule-based symbolic execution for legal aid eligibility determination.",
      "problem": "Manual legal aid eligibility review is time-consuming and inconsistent. Deep learning models are opaque, while rule-based systems are too rigid.",
      "approach": "Built a five-component hybrid architecture: EnhancedLegalBERT (multi-task Transformer), EligibilityPredictor, DomainClassifier, LegalGAT (Graph Attention Network), and Prolog rule engine. Coordinated by IntelligentHybridPredictor with isotonic regression calibration.",
      "architecture": "Text Path (neural models) + Structured Facts Path (GNN + Prolog) → Hybrid Orchestrator → Confidence Calibration → Weighted Ensemble → Final Decision",
      "results": "Full hybrid setup achieves F1: 0.985, outperforming best 4-model neural ensemble (F1: 0.982). Symbolic module catches rule-specific errors as safety layer.",
      "techStack": ["Python", "PyTorch", "LegalBERT", "Graph Neural Networks", "SWI-Prolog", "Transformers"],
      "githubUrl": "https://github.com/mohitkumar/hybex-law",
      "liveUrl": "",
      "status": "active",
      "type": "research"
    },
    {
      "slug": "nexus",
      "title": "Nexus: Multi-Agent Research Automation",
      "category": "Reasoning",
      "tagline": "3-agent system for automated research discovery and synthesis",
      "metric": "75% Manual Effort Reduction",
      "tags": ["Multi-Agent", "NLP Automation", "LangGraph", "Flask", "AI Research"],
      "description": "An advanced AI-powered research system that automates gathering, analyzing, and generating structured research content using three specialized AI agents.",
      "problem": "Traditional research involves time-consuming manual searches, information filtering, and content structuring with inefficiencies and inconsistencies.",
      "approach": "Built modular AI-driven agentic architecture with Research Agent (data collection from Google, Wikipedia, ArXiv), Reporting Agent (content synthesis), and Storage Agent (multi-format output). Uses LangGraph for workflow orchestration.",
      "architecture": "Flask Backend + LangGraph Workflow → Research Agent → Reporting Agent → Storage Agent → React Frontend with Framer Motion",
      "results": "Real-time generation of 800+ word articles in <20 seconds. 100% structured output across .md, .json, .pdf formats. Fact-checking via Google Fact Check API.",
      "techStack": ["Python", "Flask", "LangGraph", "React", "Tailwind CSS", "Framer Motion", "Google Gemini API"],
      "githubUrl": "https://github.com/mohitkumar/nexus",
      "liveUrl": "",
      "status": "active",
      "type": "independent"
    },
    {
      "slug": "parking-detection",
      "title": "Parking Slot Vacancy Detection",
      "category": "Vision",
      "categories": ["Vision"],
      "tagline": "SwinMask2Former + GLCM for layout-free parking detection",
      "metric": "mAP50: 98.99%",
      "precision": "mAP75: 95.14%",
      "tags": ["Computer Vision", "Swin Transformer", "Mask2Former", "GLCM", "Instance Segmentation"],
      "description": "A novel end-to-end framework for layout-free parking vacancy detection achieving pixel-accurate instance segmentation of vehicles and dynamic slot inference.",
      "problem": "Vision-based parking systems require predefined layouts and use inaccurate bounding boxes, limiting flexibility and precision.",
      "approach": "Augmented Swin Transformer backbone with GLCM texture features via FiLM layer. Dynamic slot inference module operates in homography-normalized BEV using spatial clustering.",
      "architecture": "Swin Transformer + GLCM → FiLM Fusion → Mask2Former Decoder → BEV Transformation → Dynamic Slot Finder → ROI Filtering",
      "results": "State-of-the-art mAP50 of 98.99% and mAP75 of 95.14%. Layout-free detection with 13ms inference time. Robust to shadows, glare, and wet surfaces.",
      "techStack": ["Python", "PyTorch", "Swin Transformer", "Mask2Former", "OpenCV", "GLCM"],
      "githubUrl": "https://github.com/mohitkumar/parking-detection",
      "liveUrl": "",
      "status": "active",
      "type": "research"
    },
    {
      "slug": "sanchalak",
      "title": "Sanchalak: Farmer Voice Assistant",
      "category": "Audio",
      "categories": ["Audio", "AgriTech"],
      "tagline": "Multilingual voice AI for government scheme eligibility",
      "metric": "<5s Latency",
      "tags": ["Voice AI", "Prolog", "LLM", "Multilingual", "FastAPI", "AgriTech"],
      "description": "A voice-driven AI assistant bridging the information gap between India's farmers and 50+ government welfare schemes through natural voice interaction.",
      "problem": "140M+ farmer families face digital/linguistic divide. Complex eligibility criteria scattered across government websites in English.",
      "approach": "Hybrid Prolog+LLM architecture: Prolog for 100% deterministic eligibility, Gemma LLM for humanized responses. Three-tier microservice architecture with FastAPI backend.",
      "architecture": "Streamlit Frontend → FastAPI Backend → Whisper STT → Azure Translator → NLU → Prolog Engine → Gemma LLM → Azure TTS",
      "results": "Sub-5s end-to-end latency. 100% accurate eligibility via Prolog rules. Multilingual support (Hindi, Tamil, Punjabi).",
      "techStack": ["Python", "FastAPI", "Prolog", "Whisper", "Azure TTS", "Gemma LLM", "Streamlit"],
      "githubUrl": "https://github.com/mohitkumar/sanchalak",
      "liveUrl": "",
      "status": "active",
      "type": "internship"
    },
    {
      "slug": "luna",
      "title": "LUNA: Logical Universal Networked Assistant",
      "category": "Audio",
      "categories": ["Audio"],
      "tagline": "Desktop AI assistant with local execution capabilities",
      "metric": "Hybrid Cloud+Local",
      "tags": ["Desktop AI", "Automation", "LLM", "Voice Interface", "PyQt5"],
      "description": "A desktop AI assistant merging cloud LLM intelligence with local Python execution, enabling both cognitive tasks and system automation.",
      "problem": "Web-based chatbots can answer questions but cannot interact with local operating system or execute commands.",
      "approach": "Intent Router classifies input into Thinking Stream (cloud LLM) or Doing Stream (local execution). Uses Groq/Cohere APIs for intelligence, PyAutoGUI/AppOpener for automation.",
      "architecture": "Wake Word → STT → Intent Router → [Groq/Cohere/Gemini Vision] OR [os/subprocess/PyAutoGUI] → TTS → PyQt5 HUD",
      "results": "Seamless voice-to-action pipeline. Real-time web scraping via Selenium. Transparent overlay GUI with futuristic HUD experience.",
      "techStack": ["Python", "PyQt5", "Groq API", "Cohere API", "Gemini Vision", "PyAutoGUI", "Selenium", "Edge TTS"],
      "githubUrl": "https://github.com/mohitkumar/luna",
      "liveUrl": "",
      "status": "active",
      "type": "independent"
    },
    {
      "slug": "har-gcnn",
      "title": "HAR-GCNN: Human Activity Recognition",
      "category": "Vision",
      "categories": ["Vision", "Healthcare"],
      "tagline": "Graph-based spatiotemporal activity classification",
      "metric": "Accuracy: 99.99%",
      "tags": ["GNN", "HAR", "Time-Series", "Sensor Data", "PAMAP2"],
      "description": "A graph-based model for human activity recognition capturing spatial and temporal dependencies in sensor data with extreme accuracy.",
      "problem": "Traditional HAR methods use shallow networks limiting pattern capture. Existing methods struggle with missing labels and noise.",
      "approach": "Proposed HAR-GCNN with single GCNN layer for graph embedding + 3 CNN layers for classification. Robust to 66% missing labels.",
      "architecture": "Sensor Graph → GCNN Layer → CNN Layers → Softmax Classification. PReLU activation, Cross-Entropy loss.",
      "results": "99.99% accuracy on PAMAP2, outperforming CNN (99.75%) and LSTM (98.10%). ~5000 parameters for lightweight deployment.",
      "techStack": ["Python", "PyTorch", "Graph Convolutional Networks", "PAMAP2 Dataset"],
      "githubUrl": "https://github.com/mohitkumar/har-gcnn",
      "liveUrl": "",
      "status": "active",
      "type": "research"
    },
    {
      "slug": "medical-audio",
      "title": "Medical Audio Classification (Samsung PRISM)",
      "category": "Audio",
      "categories": ["Audio"],
      "tagline": "Zero-shot body sound analysis with CLIP/CLAP",
      "metric": "10+ Sound Classes",
      "tags": ["Audio AI", "CLIP", "CLAP", "Healthcare", "Zero-Shot", "Medical"],
      "description": "Fine-tuned multimodal models for zero-shot medical body sound classification across heart, respiratory, and bowel sounds.",
      "problem": "Medical audio diagnostics require expensive labeled datasets. Need zero-shot capability for new sound classes.",
      "approach": "Fine-tuned CLAP and CLIP on 20k+ medical audio samples. Built annotation + preprocessing pipeline with t-SNE visualization for embedding analysis.",
      "architecture": "Audio Preprocessing → CLAP/CLIP Encoder → t-SNE Visualization → Zero-Shot Classification",
      "results": "Zero-shot analysis across 10+ body sound classes. High-quality embeddings validated via t-SNE plots.",
      "techStack": ["Python", "PyTorch", "CLIP", "CLAP", "PhysioNet", "AudioSet"],
      "githubUrl": "https://github.com/mohitkumar/medical-audio",
      "liveUrl": "",
      "status": "active",
      "type": "internship"
    },
    {
      "slug": "agricure",
      "title": "AgriCure: Agricultural Disease Classifier",
      "category": "Vision",
      "categories": ["Vision", "AgriTech"],
      "tagline": "Lightweight transformer for edge deployment",
      "metric": "92.5% in 150ms",
      "tags": ["AgriTech", "Transformers", "Edge AI", "Disease Detection"],
      "description": "A high-speed agricultural disease classification system optimized for edge deployment with minimal latency.",
      "problem": "Farmers need quick, accurate crop disease detection on low-power devices without internet connectivity.",
      "approach": "Built lightweight transformer-based classifier optimized for mobile/edge deployment with fast inference.",
      "architecture": "Image Input → Lightweight Transformer → Disease Classification → Treatment Recommendations",
      "results": "92.5% accuracy with 150ms inference time. Suitable for edge deployment on mobile devices.",
      "techStack": ["Python", "PyTorch", "Vision Transformers", "Mobile Optimization"],
      "githubUrl": "https://github.com/mohitkumar/agricure",
      "liveUrl": "",
      "status": "active",
      "type": "independent"
    },
    {
      "slug": "xray-normalization",
      "title": "Gated Multi-Domain CUT for X-ray",
      "category": "Vision",
      "categories": ["Vision", "Healthcare"],
      "tagline": "Attention-based X-ray intensity normalization",
      "metric": "SSIM: 0.9858",
      "tags": ["Medical Imaging", "GANs", "CUT", "X-ray", "Attention"],
      "description": "A novel Gated Multi-Domain CUT model for efficient X-ray normalization across multiple intensity levels using a single unified generator.",
      "problem": "X-ray images vary in intensity levels across different machines and settings, affecting diagnostic consistency.",
      "approach": "Designed attention-based architecture with hybrid contrastive loss ensuring high anatomical fidelity while modulating image style.",
      "architecture": "X-ray Input → Gated Multi-Domain Generator → Attention Layers → Hybrid Contrastive Loss → Normalized Output",
      "results": "SSIM of 0.9858, outperforming CycleGAN, StarGAN, and standard CUT baselines.",
      "techStack": ["Python", "PyTorch", "CUT Architecture", "Attention Mechanisms"],
      "githubUrl": "https://github.com/mohitkumar/xray-normalization",
      "liveUrl": "",
      "status": "active",
      "type": "research"
    }
  ]
}
